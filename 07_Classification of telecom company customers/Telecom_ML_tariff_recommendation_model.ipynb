{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913767e0",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Examining-data-from-a-file\" data-toc-modified-id=\"Examining-data-from-a-file-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Examining data from a file</a></span></li><li><span><a href=\"#Splitting-the-original-data-into-training,-validation-and-test-samples\" data-toc-modified-id=\"Splitting-the-original-data-into-training,-validation-and-test-samples-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Splitting the original data into training, validation and test samples</a></span></li><li><span><a href=\"#Exploring-the-quality-of-different-models-by-changing-hyperparameters\" data-toc-modified-id=\"Exploring-the-quality-of-different-models-by-changing-hyperparameters-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exploring the quality of different models by changing hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree-Classifier\" data-toc-modified-id=\"Decision-Tree-Classifier-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Decision Tree Classifier</a></span></li><li><span><a href=\"#Random-Forest-Classifier\" data-toc-modified-id=\"Random-Forest-Classifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Random Forest Classifier</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Model-testing\" data-toc-modified-id=\"Model-testing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model testing</a></span></li><li><span><a href=\"#Model-sanity-check\" data-toc-modified-id=\"Model-sanity-check-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model sanity check</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bf01d",
   "metadata": {},
   "source": [
    "# Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906edb6",
   "metadata": {},
   "source": [
    "Mobile operator Megaline has found out that many customers use archived tariffs. We, the company's data scientists, want to build a system that can analyse customer behaviour and offer users a new tariff: Smart or Ultra.\n",
    "\n",
    "We have data on the behaviour of customers who have already switched to these tariffs (from the project \"Statistical Data Analysis\"). We need to build a model for the classification problem, which selects the appropriate tariff. No preprocessing of the data is needed - we have already done it.\n",
    "\n",
    "Let's build a model with the highest possible value of the `accuracy` metric. For the project to be successful, we need to get the percentage of correct answers to at least 0.75. Let's test `accuracy' on a test sample by ourselves.\n",
    "\n",
    "**Data description**.\n",
    "\n",
    "Each object in the dataset is information about the behaviour of one user over a month. Known:\n",
    "\n",
    "* calls - number of calls,\n",
    "* minutes - total duration of calls in minutes,\n",
    "* messages - number of sms messages,\n",
    "* mb_used - used Internet traffic in Mb,\n",
    "* is_ultra - which tariff was used during the month (\"Ultra\" - 1, \"Smart\" - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7ae757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa591a",
   "metadata": {},
   "source": [
    "## Examining data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489b5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('users_behavior.csv')\n",
    "    \n",
    "except:\n",
    "    df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581655eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>22.0</td>\n",
       "      <td>131.53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4877.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>71.0</td>\n",
       "      <td>499.54</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9791.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>93.0</td>\n",
       "      <td>727.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17723.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>84.0</td>\n",
       "      <td>517.05</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10945.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>71.0</td>\n",
       "      <td>500.65</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13803.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>66.0</td>\n",
       "      <td>437.75</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25108.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>51.0</td>\n",
       "      <td>360.56</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19683.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>73.0</td>\n",
       "      <td>478.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14927.91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>108.0</td>\n",
       "      <td>789.17</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32670.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>39.0</td>\n",
       "      <td>242.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20480.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "519    22.0   131.53       5.0   4877.94         0\n",
       "2455   71.0   499.54      56.0   9791.01         0\n",
       "3120   93.0   727.11      11.0  17723.74         0\n",
       "610    84.0   517.05      81.0  10945.58         1\n",
       "1971   71.0   500.65      44.0  13803.46         0\n",
       "1265   66.0   437.75      22.0  25108.55         0\n",
       "2393   51.0   360.56      53.0  19683.68         0\n",
       "2101   73.0   478.97       0.0  14927.91         1\n",
       "1021  108.0   789.17      12.0  32670.36         1\n",
       "2513   39.0   242.71       0.0  20480.11         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "display(df.sample(10))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a7dfe",
   "metadata": {},
   "source": [
    "We carried out a high-level examination of the data presented in the dataset. Considering that the data have been pre-processed in the previous stages of the project, everything looks very correct, without the need for additional actions and manipulations to process the data.\n",
    "\n",
    "It is possible to start further work on model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327639c8",
   "metadata": {},
   "source": [
    "## Splitting the original data into training, validation and test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99578f72",
   "metadata": {},
   "source": [
    "Our goal is to develop a model that predicts the best tariff plan for customers. Since we do not have a test dataset at our disposal, we will divide the available original dataset into three samples: **training, validation and test samples in the proportion 3:1:1**, i.e. 60% : 20% : 20% respectively.\n",
    "\n",
    "The target feature is the column with the feature of the predicted tariff: `is_ultra`. All other columns of the table act as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00afbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 1928 объектов\n",
      "Размер валидационной выборки: 643 объекта\n",
      "Размер тестовой выборки: 643 объекта\n"
     ]
    }
   ],
   "source": [
    "# With train_test_split we split our dataset into appropriate samples \n",
    "\n",
    "df_train, df_valid = train_test_split(df, random_state=12345, test_size=0.4)\n",
    "df_valid, df_test = train_test_split(df_valid, random_state=12345, test_size=0.5)\n",
    "print('Размер обучающей выборки:', df_train.shape[0], 'объектов')\n",
    "print('Размер валидационной выборки:', df_valid.shape[0], 'объекта')\n",
    "print('Размер тестовой выборки:', df_test.shape[0], 'объекта')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ad2b8",
   "metadata": {},
   "source": [
    "Having split our initial dataset in the required proportion, we can then proceed to building and investigating different models, with the aim of choosing the best one in terms of maximising the `accuracy' metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6369cd94",
   "metadata": {},
   "source": [
    "## Exploring the quality of different models by changing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639eac0",
   "metadata": {},
   "source": [
    "Many machine learning libraries require features to be stored in separate variables. \n",
    "\n",
    "So for each of our samples we declare two variables: `features` and `target`, into which we store the features and the target feature, respectively. The column `is_ultra` acts as the target feature. All other columns are features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259fafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning features and target feature to respective variables - Training set\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# Assigning features and target feature to respective variables - Validation set\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "# Assigning features and target feature to respective variables - Testing set\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971267d6",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89133148",
   "metadata": {},
   "source": [
    "We first investigate the Decision Tree Classifier model by changing the hyperparameter for maximum tree depth - `max_depth` - from 1 to 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98a1cd",
   "metadata": {},
   "source": [
    "We will explore the model by enumerating ten different hyperparameters and obtain quality scores for each model on the validation dataset. To ensure that our model is not overfitted, we can derive quality scores for both the validation and training datasets simultaneously. And analyze the difference in the scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d600e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth = 1 \tAccuracy_valid = 0.7542768273716952, Accuracy_train = 0.7577800829875518\n",
      "Max_depth = 2 \tAccuracy_valid = 0.7822706065318819, Accuracy_train = 0.7878630705394191\n",
      "Max_depth = 3 \tAccuracy_valid = 0.7853810264385692, Accuracy_train = 0.8075726141078838\n",
      "Max_depth = 4 \tAccuracy_valid = 0.7791601866251944, Accuracy_train = 0.8106846473029046\n",
      "Max_depth = 5 \tAccuracy_valid = 0.7791601866251944, Accuracy_train = 0.8200207468879668\n",
      "Max_depth = 6 \tAccuracy_valid = 0.7838258164852255, Accuracy_train = 0.8376556016597511\n",
      "Max_depth = 7 \tAccuracy_valid = 0.7822706065318819, Accuracy_train = 0.8558091286307054\n",
      "Max_depth = 8 \tAccuracy_valid = 0.7791601866251944, Accuracy_train = 0.8625518672199171\n",
      "Max_depth = 9 \tAccuracy_valid = 0.7822706065318819, Accuracy_train = 0.8812240663900415\n",
      "Max_depth = 10 \tAccuracy_valid = 0.7744945567651633, Accuracy_train = 0.8890041493775933\n",
      "\n",
      "Accuracy лучшей модели \"Дерево Решений\" на валидационном наборе: 0.7853810264385692 \n",
      "Глубина дерева: 3\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_max_depth = 0\n",
    "\n",
    "for depth in range(1,11):\n",
    "    dtc_model = DecisionTreeClassifier(random_state=12345, max_depth=depth) # initialize model\n",
    "    dtc_model.fit(features_train, target_train) # fitting the model on train set\n",
    "    predictions = dtc_model.predict(features_valid) # obtaining the model predictions on the validation set\n",
    "    result = accuracy_score(target_valid, predictions) # examine the quality of the model on the validation set by calculating the accuracy metric\n",
    "    predictions_train = dtc_model.predict(features_train) # obtaining the model predictions on the train set\n",
    "    result_train = accuracy_score(target_train, predictions_train) # examine the quality of the model on the train set by calculating the accuracy metric\n",
    "    print(f'Max_depth = {depth} \\tAccuracy_valid = {result}, Accuracy_train = {result_train}')\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_max_depth = depth\n",
    "        \n",
    "print('\\nAccuracy лучшей модели \"Дерево Решений\" на валидационном наборе:', best_result, '\\nГлубина дерева:', best_max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23f496",
   "metadata": {},
   "source": [
    "The value of the `accuracy` metric on the validation set when the tree depth hyperparameter is changed ranges from 75% to 79%. The best metric value =78.54% is achieved with tree depth equal to 3.\n",
    "\n",
    "At the same time, comparing the values of the quality scores on the validation and training dataset, we do not observe a sharp drop in the predicted scores between the training and validation datasets for each respective model. We can conclude that our model is not over-trained. Yes, with increasing tree depth, there is a slight increase in the difference, but this is more indicative of the natural behaviour of the model rather than overtraining it. \n",
    "\n",
    "Next we investigate another classification algorithm: Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f322c",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb0c87",
   "metadata": {},
   "source": [
    "We will investigate the Random Forest Classifier model by varying the hyperparameter of the number of trees - `n_estimators` - from 5 to 55 trees in the forest in each individual model, in increments of 5 trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6904e457",
   "metadata": {},
   "source": [
    "We will explore the model by enumerating eleven different hyperparameters and obtain quality scores for each model on the validation dataset. To ensure that our model is not overfitted, we can derive quality scores for both the validation and training datasets simultaneously. And analyze the difference in the scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b6d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_estimators = 5 \tAccuracy_valid = 0.749611197511664, Accuracy_train = 0.9678423236514523\n",
      "N_estimators = 10 \tAccuracy_valid = 0.7853810264385692, Accuracy_train = 0.9823651452282157\n",
      "N_estimators = 15 \tAccuracy_valid = 0.7838258164852255, Accuracy_train = 0.9896265560165975\n",
      "N_estimators = 20 \tAccuracy_valid = 0.7869362363919129, Accuracy_train = 0.9891078838174274\n",
      "N_estimators = 25 \tAccuracy_valid = 0.7838258164852255, Accuracy_train = 0.995850622406639\n",
      "N_estimators = 30 \tAccuracy_valid = 0.7838258164852255, Accuracy_train = 0.995850622406639\n",
      "N_estimators = 35 \tAccuracy_valid = 0.7776049766718507, Accuracy_train = 0.9984439834024896\n",
      "N_estimators = 40 \tAccuracy_valid = 0.7838258164852255, Accuracy_train = 0.9974066390041494\n",
      "N_estimators = 45 \tAccuracy_valid = 0.7884914463452566, Accuracy_train = 0.9984439834024896\n",
      "N_estimators = 50 \tAccuracy_valid = 0.7916018662519441, Accuracy_train = 0.9979253112033195\n",
      "N_estimators = 55 \tAccuracy_valid = 0.7853810264385692, Accuracy_train = 0.9989626556016598\n",
      "\n",
      "Accuracy лучшей модели \"Случайный Лес\" на валидационном наборе: 0.7916018662519441 \n",
      "Число деревьев в лесу: 50\n"
     ]
    }
   ],
   "source": [
    "best_result = 0\n",
    "best_n_estimators = 0\n",
    "\n",
    "for est in range(5,56,5):\n",
    "    rfc_model = RandomForestClassifier(random_state=12345, n_estimators=est) # initializing the model\n",
    "    rfc_model.fit(features_train, target_train) # fitting the model on training set\n",
    "    predictions = rfc_model.predict(features_valid) # obraining model predictions\n",
    "    result = accuracy_score(target_valid, predictions) # examining the accuracy metric on validation set\n",
    "    predictions_train = rfc_model.predict(features_train) # obraining model predictions on validation set\n",
    "    result_train = accuracy_score(target_train, predictions_train) # examining the accuracy metric on training set\n",
    "    print(f'N_estimators = {est} \\tAccuracy_valid = {result}, Accuracy_train = {result_train}')\n",
    "    #print('N_estimators =', est, '\\tAccuracy =', result)\n",
    "    if result > best_result:\n",
    "        best_result = result\n",
    "        best_n_estimators = est\n",
    "        \n",
    "print('\\nAccuracy лучшей модели \"Случайный Лес\" на валидационном наборе:', best_result, '\\nЧисло деревьев в лесу:', best_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83569b",
   "metadata": {},
   "source": [
    "The value of the `accuracy` metric when changing the hyperparameter number of trees in the forest ranges from 74.965% to 79.16%. The best value of metric =79.16% is achieved when the number of trees in the forest is 50.\n",
    "\n",
    "At the same time, comparing the quality scores on the validation and training dataset, we observe a significant difference in the predicted scores between the training and validation datasets for each respective model. We can conclude that our model is over-trained.\n",
    "\n",
    "Next, we investigate another classification algorithm: Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a3617",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd64bd",
   "metadata": {},
   "source": [
    "Let's investigate the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04faf565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели \"Логистическая Регрессия\": 0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345) # initializing model\n",
    "lr_model.fit(features_train, target_train) # fitting model on training set\n",
    "predictions = lr_model.predict(features_valid) # getting model predictions\n",
    "result = accuracy_score(target_valid, predictions) # calculating accuracy on validation set\n",
    "\n",
    "print('Accuracy модели \"Логистическая Регрессия\":', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edbeae6",
   "metadata": {},
   "source": [
    "The value of the `accuracy' metric when applying the Logistic Regression algorithm is 71.07%, which is the lowest value among all the models built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0f946",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c0cd6",
   "metadata": {},
   "source": [
    "The quality of different models built using three different algorithms \"Decision Tree\", \"Random Forest\", \"Logistic Regression\" was investigated.\n",
    "\n",
    "In the course of the study we obtained:\n",
    "- The model building algorithm \"Decision Tree\" has maximum value of `accuracy` = 78.54%, with tree depth equal to 3\n",
    "- The model building algorithm \"Random Forest\" has maximum value of `accuracy` = 79.16%, with number of trees in the forest equal to 50\n",
    "- The model building algorithm \"Logistic Regression\" has a value of `accuracy` = 71.07%\n",
    "\n",
    "Although the model built using \"Logistic Regression\" algorithm is the fastest, in terms of computational performance, in our case it is the least accurate with a significant lag (`accuracy` = 71.07%). \n",
    "\n",
    "The most accurate model in our case with a metric score of `accuracy` = 79.16% is the model built using the Random Forest algorithm with the number of trees in the forest equal to 50. However, the large number of trees in the forest makes this model slow and resource consuming to learn and run. In our situation, in order to optimize the processing time and without relative loss of model prediction quality, we could also consider a Decision Tree model with tree depth equal to 3, at which `accuracy' score = 78.54%.\n",
    "\n",
    "The conditions of the task envisage maximizing the `accuracy` metric. Accordingly, we further test the model with the maximum value of the `accuracy` metric - the model \"Random Forest\", with the number of trees equal to 50.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc7488",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105a23a9",
   "metadata": {},
   "source": [
    "The model that maximizes the value of the `accuracy` metric is built using the Random Forest algorithm with the number of trees in the forest equal to 50. Let's test the behaviour of this model on a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ee93184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy наилучшей модели на тестовой выборке: 0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=50) # Initializing the model with the maximum value of the accuracy metric\n",
    "model.fit(features_train, target_train) # fitting the model on training set\n",
    "predictions = model.predict(features_test) # getting the model predictions on test set\n",
    "result = accuracy_score(target_test, predictions) # calculating accuracy on test set\n",
    "\n",
    "print('Accuracy наилучшей модели на тестовой выборке:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d97bb4",
   "metadata": {},
   "source": [
    "The predictive accuracy of the model on the test sample was even slightly higher than on the validation set and equals 79.32%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d332a5",
   "metadata": {},
   "source": [
    "## Model sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135ed0e",
   "metadata": {},
   "source": [
    "In order to assess the adequacy of the model's behaviour or to check its sanity, it is recommended to compare the model with a random constant model.\n",
    "\n",
    "In our case, the model should predict the choice with respect to one of the two tariff plans: 0-Smart, 1-Ultra. Let us look at the distribution of the target feature values in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9953be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693528\n",
       "1    0.306472\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_ultra.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0185539",
   "metadata": {},
   "source": [
    "In the original dataset, the Smart tariff represents 69% of the total number of objects. As a random model, let us define a constant model that will always predict the Smart tariff. That is, the accuracy - `accuracy' - of such a model would be approximately 69%. At the same time, the predictive accuracy of the best model we built was 79.32%, which is higher than the constant model. Thus, we can conclude that our model is adequate."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2553,
    "start_time": "2022-04-16T20:08:40.204Z"
   },
   {
    "duration": 63,
    "start_time": "2022-04-16T20:08:42.760Z"
   },
   {
    "duration": 61,
    "start_time": "2022-04-16T20:08:42.828Z"
   },
   {
    "duration": 12,
    "start_time": "2022-04-16T20:08:42.891Z"
   },
   {
    "duration": 16,
    "start_time": "2022-04-16T20:08:42.926Z"
   },
   {
    "duration": 127,
    "start_time": "2022-04-16T20:08:42.944Z"
   },
   {
    "duration": 1948,
    "start_time": "2022-04-16T20:08:43.073Z"
   },
   {
    "duration": 37,
    "start_time": "2022-04-16T20:08:45.025Z"
   },
   {
    "duration": 318,
    "start_time": "2022-04-16T20:08:45.064Z"
   },
   {
    "duration": 13,
    "start_time": "2022-04-16T20:08:45.384Z"
   },
   {
    "duration": 1590,
    "start_time": "2022-04-17T06:37:13.448Z"
   },
   {
    "duration": 76,
    "start_time": "2022-04-17T06:37:15.041Z"
   },
   {
    "duration": 41,
    "start_time": "2022-04-17T06:37:15.118Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-17T06:37:15.161Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-17T06:37:15.170Z"
   },
   {
    "duration": 93,
    "start_time": "2022-04-17T06:37:15.177Z"
   },
   {
    "duration": 84,
    "start_time": "2022-04-17T06:37:15.272Z"
   },
   {
    "duration": 1226,
    "start_time": "2022-04-17T06:37:15.357Z"
   },
   {
    "duration": 22,
    "start_time": "2022-04-17T06:37:16.585Z"
   },
   {
    "duration": 204,
    "start_time": "2022-04-17T06:37:16.608Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-17T06:37:16.814Z"
   },
   {
    "duration": 85,
    "start_time": "2022-04-17T06:49:22.504Z"
   },
   {
    "duration": 80,
    "start_time": "2022-04-17T06:50:59.473Z"
   },
   {
    "duration": 79,
    "start_time": "2022-04-17T06:51:29.866Z"
   },
   {
    "duration": 80,
    "start_time": "2022-04-17T06:53:45.794Z"
   },
   {
    "duration": 80,
    "start_time": "2022-04-17T06:54:27.289Z"
   },
   {
    "duration": 76,
    "start_time": "2022-04-17T06:54:52.296Z"
   },
   {
    "duration": 77,
    "start_time": "2022-04-17T06:55:58.681Z"
   },
   {
    "duration": 80,
    "start_time": "2022-04-17T07:02:35.971Z"
   },
   {
    "duration": 1292,
    "start_time": "2022-04-17T07:14:06.700Z"
   },
   {
    "duration": 1277,
    "start_time": "2022-04-17T07:15:49.417Z"
   },
   {
    "duration": 1288,
    "start_time": "2022-04-17T07:20:50.114Z"
   },
   {
    "duration": 1349,
    "start_time": "2022-04-17T07:47:47.182Z"
   },
   {
    "duration": 68,
    "start_time": "2022-04-17T07:47:48.533Z"
   },
   {
    "duration": 37,
    "start_time": "2022-04-17T07:47:48.603Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-17T07:47:48.641Z"
   },
   {
    "duration": 14,
    "start_time": "2022-04-17T07:47:48.650Z"
   },
   {
    "duration": 67,
    "start_time": "2022-04-17T07:47:48.666Z"
   },
   {
    "duration": 84,
    "start_time": "2022-04-17T07:47:48.735Z"
   },
   {
    "duration": 1217,
    "start_time": "2022-04-17T07:47:48.820Z"
   },
   {
    "duration": 1321,
    "start_time": "2022-04-17T07:47:50.038Z"
   },
   {
    "duration": 20,
    "start_time": "2022-04-17T07:47:51.360Z"
   },
   {
    "duration": 194,
    "start_time": "2022-04-17T07:47:51.382Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-17T07:47:51.577Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
