{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbf2253",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-preparation\" data-toc-modified-id=\"Data-preparation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#BERT.-Embeddings-preparation\" data-toc-modified-id=\"BERT.-Embeddings-preparation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>BERT. Embeddings preparation</a></span></li></ul></li><li><span><a href=\"#Models-training\" data-toc-modified-id=\"Models-training-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Models training</a></span><ul class=\"toc-item\"><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>BERT</a></span></li></ul></li><li><span><a href=\"#Testing-model\" data-toc-modified-id=\"Testing-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Testing model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaa4eb",
   "metadata": {},
   "source": [
    "# Project description: Search for toxic comments for the online shop Wikishop - with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3954e7aa",
   "metadata": {},
   "source": [
    "The online shop Wikshop is launching a new service. Users can now edit and add to product descriptions, just like in wiki communities. That is, customers suggest their edits and comment on others' changes. \n",
    "\n",
    "The shop needs a tool that will search for toxic comments and send them for moderation.\n",
    "\n",
    "Let's train the model to classify comments into positive and negative. We have a data set with markup on the toxicity of edits.\n",
    "\n",
    "Let's build a model with an F1 quality metric value of not less than 0.75.\n",
    "\n",
    "**Data description**.\n",
    "\n",
    "The data is in the file `/datasets/toxic_comments.csv`.\n",
    "\n",
    "The `text` column in it contains the text of the comment and `toxic` contains the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687c5177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\serghei\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\serghei\\anaconda3\\lib\\site-packages (4.22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: pymystem3 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from pymystem3) (2.26.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->pymystem3) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\serghei\\anaconda3\\lib\\site-packages (from requests->pymystem3) (3.2)\n"
     ]
    }
   ],
   "source": [
    "# loading and importing required libraries\n",
    "\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0ebd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Serghei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Serghei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Serghei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from tqdm import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f607f",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f25e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and reading data\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv', index_col=0).reset_index(drop=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78885c16",
   "metadata": {},
   "source": [
    "**Data overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8abf04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143523</th>\n",
       "      <td>\"\\n\\n September 2010 \\n\\n Please do not vandal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>\"\\n\\nNo, Thanatos666 and Dr.K. are not \"\"pushi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132796</th>\n",
       "      <td>On the contrary-it is the germans that have al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139971</th>\n",
       "      <td>That'll do fine. Thanks.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39648</th>\n",
       "      <td>Oh spare me the drama. What are you trying to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "143523  \"\\n\\n September 2010 \\n\\n Please do not vandal...      0\n",
       "5405    \"\\n\\nNo, Thanatos666 and Dr.K. are not \"\"pushi...      0\n",
       "132796  On the contrary-it is the germans that have al...      0\n",
       "139971                           That'll do fine. Thanks.      0\n",
       "39648   Oh spare me the drama. What are you trying to ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info(), df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04715abb",
   "metadata": {},
   "source": [
    "**Checking the class balance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75dd9344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd93ecd",
   "metadata": {},
   "source": [
    "**Conclusion:**.\n",
    "\n",
    "1. There are 159292 rows in the dataset, no missing values.\n",
    "2. There are noises in the text (hyphenation, apostrophes).\n",
    "3. The target feature is imbalanced. The ratio of negative to positive class is 9:1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad477a2",
   "metadata": {},
   "source": [
    "The problem will be solved in two ways: \n",
    "1. by building a features matrix with calculation of TF-IDF values,\n",
    "2. by forming embeddings of the pre-trained BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee523723",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07960085",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf81517",
   "metadata": {},
   "source": [
    "Will write lemmatisation and text cleaning functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d3092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemm_list = nltk.word_tokenize(text)\n",
    "    lemm_text = ' '.join([lemmatizer.lemmatize(w) for w in lemm_list])  \n",
    "    return lemm_text\n",
    "\n",
    "def clear_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z']\", ' ', text)\n",
    "    return ' '.join(text.split()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694bb34",
   "metadata": {},
   "source": [
    "Will apply the defined functions to clean up our dataset corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736e8f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b399f771e5514469b3d55f56c33194cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['lemm_text'] = df['text'].progress_apply(lambda x: lemmatize(clear_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "585d2b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139698</th>\n",
       "      <td>you suck messing with honduras! \\n\\nFuck you\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>you suck messing with honduras Fuck you anon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72946</th>\n",
       "      <td>\"\\n\\nExcept this article is extremely biased b...</td>\n",
       "      <td>0</td>\n",
       "      <td>Except this article is extremely biased becaus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "139698  you suck messing with honduras! \\n\\nFuck you\\n...      1   \n",
       "72946   \"\\n\\nExcept this article is extremely biased b...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "139698       you suck messing with honduras Fuck you anon  \n",
       "72946   Except this article is extremely biased becaus...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc3342",
   "metadata": {},
   "source": [
    "Will split the dataset into training and test samples at a ratio of 80:20, vectorise the texts, and define the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e57aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['lemm_text'], df['toxic'], stratify=df.toxic, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d1c202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы X_train: (127433, 144000)\n",
      "Размер матрицы X_test: (31859, 144000)\n"
     ]
    }
   ],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "X_train = count_tf_idf.fit_transform(X_train)\n",
    "X_test = count_tf_idf.transform(X_test)\n",
    "\n",
    "print(\"Размер матрицы X_train:\", X_train.shape)\n",
    "print(\"Размер матрицы X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425c603e",
   "metadata": {},
   "source": [
    "The features and samples for model training by building TF-IDF vectors are ready. Let us proceed to prepare embeddings to solve the problem using the pre-trained BERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b673a2",
   "metadata": {},
   "source": [
    "### BERT. Embeddings preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a27b83",
   "metadata": {},
   "source": [
    "Since the BERT model is quite resource-intensive and the embeddings take a long time to generate, we decided to limit ourselves to a sample of 500 random texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78681481",
   "metadata": {},
   "source": [
    "Will read our source file again and generate a new random dataset of 500 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c694a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv', index_col=0).reset_index(drop=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8561b0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expert Categorizers  \\n\\nWhy is there no menti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\n\\n Noise \\n\\nfart*  talk. \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An indefinite block is appropriate, even for a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't understand why we have a screenshot of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello! Some of the people, places or things yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Expert Categorizers  \\n\\nWhy is there no menti...      0\n",
       "1                     \"\\n\\n Noise \\n\\nfart*  talk. \"      1\n",
       "2  An indefinite block is appropriate, even for a...      0\n",
       "3  I don't understand why we have a screenshot of...      0\n",
       "4  Hello! Some of the people, places or things yo...      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert = df.sample(500, random_state=12345).reset_index(drop = True) \n",
    "df_bert.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d8f2c",
   "metadata": {},
   "source": [
    "Let's load the pre-trained model and initialize the tokenizer. Note that the BERT model does not require a lemmatization step, as it understands the word forms itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fd58aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (transformers.BertModel, transformers.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Loading the pre-trained model and initialising the tokeniser \n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5871507",
   "metadata": {},
   "source": [
    "BERT's tokenizer splits each sentence into tokens (words). It then adds the special tokens that are needed to classify the sentence (namely the `[CLS]` token at the first position and `[SEP]` at the end of the sentence).\n",
    "\n",
    "The next step is to replace each token with its identifier from the embeddings table, which we get along with the pre-built model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145de49",
   "metadata": {},
   "source": [
    "Tokenising all comments. Also note that the BERT model has a limit of 512 token sequence length, otherwise, indexing error will occur later. Therefore, with the parameter `max_length=512` we will limit the token sequence to 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aeab5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dd4d2d76da47dbaa1a18f1502fb5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = df_bert['text'].progress_apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dfe72cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max(len(i) for i in tokenized), tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b415bba",
   "metadata": {},
   "source": [
    "We have converted each sentence in the dataset into a list of identifiers. The dataset is now a list of lists. Before the BERT model could process it on the input, we have to bring the lengths of all vectors to the same size, by adding zeros to the shorter vectors (padding).\n",
    "\n",
    "Let's add zeros and create a mask of important tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ec60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3847fe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(500, 512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(padded.shape, attention_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9020429",
   "metadata": {},
   "source": [
    "Thus, we have a matrix/tensor that can be passed to BERT.\n",
    "\n",
    "Let's convert the data into tensor format - multidimensional vectors in the torch library. The embeddings will be created in batches of 50 rows each. To speed up the calculation, let's indicate in the torch library with function `no_grad()` that no gradient is needed - we won't teach BERT model.\n",
    "\n",
    "Then, will extract the required elements from the obtained tensor and add them to the list of all embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f67dab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48fa72f07f845bd9c2d814f36687559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ba8f1",
   "metadata": {},
   "source": [
    "Compile all the embeddings into a features matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "082427d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356f72b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_bert.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee9a4d",
   "metadata": {},
   "source": [
    "The `features_bert` variable now contains an array that consists of the embeddings of all the sentences in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748c96a",
   "metadata": {},
   "source": [
    "**Conclusion of Stage 1:**\n",
    "\n",
    "1. We have loaded the data representing comments with markup about toxicity.\n",
    "2. Prepared both TF-IDF features and embeddings derived from the BERT model.\n",
    "\n",
    "We can proceed to training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d419c11",
   "metadata": {},
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e83619",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4adcb",
   "metadata": {},
   "source": [
    "**Models initialization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7326cae",
   "metadata": {},
   "source": [
    "Will train different models with different hyperparameters. \n",
    "\n",
    "Will create a list to find the best hyperparameters for the models, and then initialise the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea6203b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to select the best hyperparameters for the models\n",
    "\n",
    "models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70194020",
   "metadata": {},
   "source": [
    "Initializing the models `Logistic Regression` and `SGD Classifier (Stochastic Gradient Descent)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edaeaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1, random_state=12345)\n",
    "\n",
    "param_grid={'penalty' : ['l1', 'l2'], \n",
    "            'fit_intercept': [True, False],\n",
    "            'max_iter' : [1000, 5000],\n",
    "            'C' : [0.001, 0.1, 0.8, 1],\n",
    "            'class_weight' : [None, 'balanced', {0: 0.9, 1: 0.1}]}\n",
    "\n",
    "models.append(('Logistic Regression', lr, param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2467d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Classifier (Stochastic Gradient Descent) \n",
    "\n",
    "sgd = SGDClassifier(n_jobs=-1, random_state=12345)\n",
    "\n",
    "param_grid = {'loss' : ['log', 'modified_huber'],\n",
    "              'penalty' : ['l1', 'l2'], \n",
    "              'fit_intercept' : [True, False],\n",
    "              'max_iter' : [5, 1000, 5000],\n",
    "              'shuffle' : [True, False],\n",
    "              'learning_rate' : ['optimal'],\n",
    "              'validation_fraction' : [0.1, 0.2, 0.3, 0.4]\n",
    "             }\n",
    "\n",
    "models.append(('SGDClassifier', sgd, param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555bacdd",
   "metadata": {},
   "source": [
    "We will define a function that will enumerate the hyperparameters of the models on the hyperparameter grid and return the best of them, and the best value of the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "663121af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for enumerating over a grid and finding the best hyperparameters of models\n",
    "\n",
    "def grid_search(model, param_grid, cv, x, y):\n",
    "    \n",
    "    ''' \n",
    "    The input function takes as its arguments the model and the hyperparameter grid from the list of models\n",
    "    as well as the number of folds for cross validation and the corresponding samples with features and target.\n",
    "    The function returns the best metric value and the best hyperparameters of the model\n",
    "    '''\n",
    "    \n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n",
    "    grid_model.fit(x, y)\n",
    "    best_estimator = grid_model.best_estimator_\n",
    "    best_score = grid_model.best_score_\n",
    "    \n",
    "    return best_score, best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14263448",
   "metadata": {},
   "source": [
    "Defining a function that will collect into a table the best **F1** metrics for each of the models on the training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e38bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_builder(models):\n",
    "    \n",
    "    table = []\n",
    "    \n",
    "    for model in models:\n",
    "        grid = grid_search(model[1], model[2], 3, X_train, y_train)\n",
    "        table.append((model[0], grid[0], grid[1]))\n",
    "        \n",
    "        print(grid)\n",
    "        \n",
    "    final_table = pd.DataFrame(table, columns=['Model', 'F1_score_CV', 'Grid'])\n",
    "        \n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53fb8734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "(0.7439326734209278, LogisticRegression(C=1, class_weight='balanced', max_iter=1000, n_jobs=-1,\n",
      "                   random_state=12345))\n",
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n",
      "(0.7505653082415282, SGDClassifier(fit_intercept=False, loss='modified_huber', max_iter=5, n_jobs=-1,\n",
      "              penalty='l1', random_state=12345))\n"
     ]
    }
   ],
   "source": [
    "final_table = table_builder(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45549dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_score_CV</th>\n",
       "      <th>Grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.743933</td>\n",
       "      <td>LogisticRegression(C=1, class_weight='balanced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.750565</td>\n",
       "      <td>SGDClassifier(fit_intercept=False, loss='modif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1_score_CV  \\\n",
       "0  Logistic Regression     0.743933   \n",
       "1        SGDClassifier     0.750565   \n",
       "\n",
       "                                                Grid  \n",
       "0  LogisticRegression(C=1, class_weight='balanced...  \n",
       "1  SGDClassifier(fit_intercept=False, loss='modif...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15871039",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290456e1",
   "metadata": {},
   "source": [
    "We will split our initial dataset into training and test samples at a ratio of 80:20. We have already prepared the features and they are in the `features_bert` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd828ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_bert_train, features_bert_test, y_bert_train, y_bert_test = train_test_split(features_bert, df_bert.toxic, test_size=0.2, stratify=df_bert.toxic, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a2c1492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы features_bert_train: (400, 768)\n",
      "Размер матрицы features_bert_test: (100, 768)\n",
      "Размер вектора y_bert_train: (400,)\n",
      "Размер вектора y_bert_test: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы features_bert_train:\", features_bert_train.shape)\n",
    "print(\"Размер матрицы features_bert_test:\", features_bert_test.shape)\n",
    "print(\"Размер вектора y_bert_train:\", y_bert_train.shape)\n",
    "print(\"Размер вектора y_bert_test:\", y_bert_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56716147",
   "metadata": {},
   "source": [
    "**Logistic regression with BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "536c66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'penalty' : ['l1', 'l2'],\n",
    "            'fit_intercept': [True, False],\n",
    "            'C' : [0.001, 0.1, 0.8, 1],\n",
    "            'max_iter' : [1000, 2000],\n",
    "            'class_weight' : [None, 'balanced', {0: 0.9, 1: 0.1}]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7270d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "\n",
      "Logistic Regression_BERT\n",
      "\n",
      "F1_score и гиперпараметры на кросс-валидации:\n",
      " (0.5632996632996633, LogisticRegression(C=1, max_iter=1000, n_jobs=-1, random_state=12345))\n"
     ]
    }
   ],
   "source": [
    "print('\\nLogistic Regression_BERT\\n\\nF1_score и гиперпараметры на кросс-валидации:\\n', grid_search(lr, param_grid, 3, features_bert_train, y_bert_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f87c3",
   "metadata": {},
   "source": [
    "**Conclusion of Stage 2:**\n",
    "\n",
    "We trained models to predict comment toxicity based on two approaches.\n",
    "\n",
    "1. For the TF-IDF approach, the SGDClassifier model, with an F1 metric value on cross validation of 0.751, proved to be the best.\n",
    "2. For the Embedding approach (for 500 records), the Logistic Regression model had a cross-validation F1 metric value of 0.56.\n",
    "\n",
    "Let us test the best model, SGDClassifier, on the test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c9a16",
   "metadata": {},
   "source": [
    "## Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb12759",
   "metadata": {},
   "source": [
    "The SGDClassifier model with TF-IDF showed the best value of F1 metric on the training sample. Let us test this model on a test sample, with the best hyperparameters identified during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d7d3f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score на тестовой выборке: SGD Classifier = 0.75\n"
     ]
    }
   ],
   "source": [
    "sgd_test = SGDClassifier(fit_intercept=False, loss='modified_huber', max_iter=5, n_jobs=-1,\n",
    "              penalty='l1', random_state=12345)\n",
    "\n",
    "sgd_test.fit(X_train, y_train)\n",
    "predictions_test = sgd_test.predict(X_test)\n",
    "\n",
    "print('F1_score на тестовой выборке: SGD Classifier =', f1_score(y_test, predictions_test).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34ec97",
   "metadata": {},
   "source": [
    "**Overall conclusion:**\n",
    "\n",
    "A total of 159292 rows representing comments from the online shop Wikishop were downloaded. To solve the problem of classifying comments for toxicity, we applied two approaches:\n",
    "1. by training the model on a feature matrix with TF-IDF values computed;\n",
    "2. by generating a feature matrix as embeddings of a pre-trained BERT model. Given the resource-intensive nature of the embedding process, we only used a subsample of 500 records randomly selected from the original dataset for this approach.\n",
    "\n",
    "For the TF-IDF approach, the `SGDClassifier' model proved to be the best, with a **F1** value on cross-validation equal to **0.751**.\n",
    "\n",
    "For the embedding approach (for 500 records), the **F1** value of the `Logistic Regression' model on cross-validation was **0.56**.\n",
    "\n",
    "The best model on training data, SGDClassifier TF-IDF, was tested on the test sample. The value of **F1_score** was **0.75**.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 6621,
    "start_time": "2022-09-18T17:40:37.394Z"
   },
   {
    "duration": 38421,
    "start_time": "2022-09-18T17:40:44.018Z"
   },
   {
    "duration": 3254,
    "start_time": "2022-09-18T17:41:22.441Z"
   },
   {
    "duration": 45,
    "start_time": "2022-09-18T17:41:25.698Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
